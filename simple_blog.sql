-- phpMyAdmin SQL Dump
-- version 5.2.1
-- https://www.phpmyadmin.net/
--
-- Host: 127.0.0.1
-- Generation Time: Apr 19, 2025 at 05:57 AM
-- Server version: 10.4.32-MariaDB
-- PHP Version: 8.2.12

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Database: `simple_blog`
--

-- --------------------------------------------------------

--
-- Table structure for table `blogs`
--

CREATE TABLE `blogs` (
  `id` int(10) UNSIGNED NOT NULL,
  `title` varchar(255) NOT NULL,
  `summary` text NOT NULL,
  `content` text NOT NULL,
  `image` varchar(255) DEFAULT NULL,
  `author_id` int(10) UNSIGNED NOT NULL,
  `created_at` datetime NOT NULL DEFAULT current_timestamp(),
  `updated_at` datetime DEFAULT current_timestamp() ON UPDATE current_timestamp()
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `blogs`
--

INSERT INTO `blogs` (`id`, `title`, `summary`, `content`, `image`, `author_id`, `created_at`, `updated_at`) VALUES
(192, 'What are AI agents and why do they matter?', 'Learn how AI agents and agentic AI systems use generative AI models and large language models to autonomously perform tasks on behalf of end users.', 'Imagine a Roomba that only told you your floors were dirty, but didn’t actually clean them for you. Helpful? Debatable. Annoying? Very.\r\n\r\nWhen ChatGPT first arrived, that was about where things stood. It could describe how to do math problems and discuss theory endlessly, but it couldn’t reliably handle a simple arithmetic question. Connecting it with an external application, however (like an online calculator) significantly improved its abilities—just like connecting Roomba’s sensors with its robot body makes it capable of actually cleaning your floor.\r\n\r\nThat simple discovery was a precursor to an evolution that’s now occurring in generative AI where large language models (LLM) power AI agents that can pursue complex goals with limited direct supervision.\r\n\r\nIn these systems, the LLM serves as the brain while additional algorithms and tools are layered on top to accomplish key tasks ranging from generating software development plans to booking plane tickets. Proof-of-concepts like AutoGPT offer examples, such as a marketing agent that looks for Reddit comments with questions about a given product and then answers them autonomously. At their best, these agents hold the promise of pursuing complex goals with minimal direct oversight—and that means removing toil and mundane linear tasks while allowing us to focus on higher-level thinking. And when you connect AI agents with other AI agents to make multi-agent systems, like we’re doing with GitHub Copilot Workspace, the realm of possibility grows exponentially.\r\n\r\nAll this is to say, if you’re a developer you’ll likely start encountering more and more instances of agentic AI in the tools you use (including on GitHub) and in the news you read. So, this feels like as good a time as any to dive into exactly what agentic AI and AI agents are, how they work on a technical level, some of the technical challenges, and what this means for software development.', '67fe184738fbc_AI-DarkMode-3.webp', 86, '2025-04-15 16:26:47', '2025-04-15 16:26:47'),
(193, 'Found means fixed: Reduce security debt at scale with GitHub security campaigns', 'Starting today, security campaigns are generally available for all GitHub Advanced Security and GitHub Code Security customers—helping organizations take control of their security debt and manage risk by unlocking collaboration between developers and security teams.', 'We get it: you’d rather spend your time shipping features than chasing security alerts. That’s why we’ve built tools like Copilot Autofix directly into pull requests, enabling teams to remediate security issues up to 60% faster, significantly reducing Mean Time to Remediation (MTTR) compared to manual fixes. Autofix helps you catch vulnerabilities before they ever make it into production, so you spend less time fixing bugs and more time coding.\r\n\r\nBut what about the vulnerabilities already lurking in your existing code? Every unresolved security finding adds to your security debt—a growing risk you can’t afford to ignore. In fact, our data shows that teams typically address only 10% of their security debt, leaving 90% of vulnerabilities unprioritized and unresolved.\r\n\r\nSecurity campaigns bridge this gap by bringing security experts and developers together, streamlining the vulnerability remediation process right within your workflow, and at scale. Using Copilot Autofix to generate code suggestions for up to 1,000 code scanning alerts at a time, security campaigns help security teams take care of triage and prioritization, while you can quickly resolve issues using Autofix—without breaking your development momentum.\r\n\r\nSecurity campaigns in action\r\nSince security campaigns were launched in public preview at GitHub Universe last year, we have seen organizations at all different stages of their security journey try them out. Whether they’ve been used to reduce security debt across an entire organization or to target alerts in critical repositories, security campaigns have delivered value for both developers and security teams in their efforts to tackle security debt.\r\n\r\nSecurity campaigns simplify life for our developers. They can easily group alerts from multiple repositories, reducing time spent on triage and prioritization while quickly remediating the most critical issues with the help of Copilot Autofix.\r\n\r\n- Jose Antonio Moreno, DevSecOps engineer, Lumen\r\nGitHub security campaigns is a game-changer for our development teams. It’s educated us about existing vulnerabilities, brought our engineers together to collaboratively tackle fixes, and significantly improved our remediation time.\r\n\r\n- GP, security engineer, Alchemy\r\nIn a sample of early customers, we found that 55% of alerts included in security campaigns were fixed, compared to around only 10% of security debt outside security campaigns, a 5.5x improvement. This shows that when alerts are included in a campaign, you can spend more time fixing the security debt, since the prioritization of which alerts to work on has already been taken care of by your security team. In fact, our data shows that alerts in campaigns get roughly twice as much developer engagement than those outside of campaigns.\r\n\r\nSecurity campaigns: how they work\r\nTriaging and prioritizing security problems already present in a codebase has to happen as part of the normal software development lifecycle. Unfortunately, when product teams are under pressure to ship faster, they often don’t have enough time to dig through their security alerts to decide which ones to address first. Luckily, in most software organizations, there is already a group of people who are experts in understanding these risks: the security team. With security campaigns, we play to the different strengths of developers and security teams in a new collaborative approach to addressing security debt.\r\n\r\nSecurity teams prioritize which risks need to be addressed across their repositories in a security campaign. Security campaigns come with predefined templates based on commonly used themes (such as the MITRE top 10 known exploited vulnerabilities) to help scope the campaign. GitHub’s security overview also provides statistics and metrics summarizing the overall risk landscape.\r\nOnce the campaign alerts are selected and a timeline is specified, the campaign is communicated to any developers who are impacted by the campaign. The work defined in a campaign is brought to developers where they work on GitHub, so that it can be planned and managed just like any other feature work.\r\n\r\nCopilot Autofix immediately starts suggesting automatic remediations for all alerts in a campaign, as well as custom help text to explain the problems. Fixing an alert becomes as easy as reviewing a diff and creating a pull request.\r\nCrucially, security campaigns are not just lists of alerts. Alongside the alerts, campaigns are complemented with notifications to ensure that developers are aware of which alert they (or their team) are responsible for. To foster stronger collaboration between developers and the security team, campaigns also have an appointed manager to oversee the campaign progress and be on hand to assist developers. And of course: security managers have an organization-level view on GitHub to track progress and collaborate with developers as needed.\r\n\r\nStarting today, you can also access several new features to plan and manage campaign-related work more effectively:\r\n\r\nDraft security campaigns: security managers can now iterate on the scope of campaigns and save them as draft campaigns before making them available to developers. With draft campaigns, security managers can ensure that the highest priority alerts are included before the work goes live.\r\nAutomated GitHub Issues: security managers can optionally create GitHub Issues in repositories that have alerts included in the campaign. These issues are created and updated automatically as the campaign progresses and can be used by teams to track, manage and discuss campaign-related work.\r\nOrganization-level security campaign statistics: security managers can now view aggregated statistics showing the progress across all currently-active and past campaigns.', '67fe1a675ef30_security-campaign-header.webp', 86, '2025-04-15 16:35:51', '2025-04-15 16:35:51'),
(204, 'March 2025 Baseline monthly digest', 'Another month has gone by and since the last Baseline monthly digest, a lot has happened! In this edition, we&#039;ll recap some posts we&#039;ve published here on web.dev, some Baseline Newly available features that have landed, and some updates to tooling in the community.', 'ESLint 0.6.0 has been released\r\nRecently, we posted about ESLint launching support for linting CSS. Part of this launch included a new ESLint rule—require-baseline—for linting the CSS features you use in your project, and whether they reach a specific Baseline threshold.\r\n\r\nRecently, ESLint launched version 0.6.0 of the @eslint/css package, which includes an important new update that renames the require-baseline rule to use-baseline. While this update is seemingly a small one, it improves on the readability of the rule. There are also some other important features and bug fixes in this release, such as the added capability of the use-baseline rule to lint nested CSS blocks. If you&#039;re using a prior version of @eslint/css, check out this update!\r\n\r\nHow to query the Web Platform Dashboard\r\nEarlier this month, we published a post about querying the Web Platform Dashboard. This dashboard can be queried on its frontend, as well as through an HTTP API. This can be potentially useful for Baseline tooling, as you can query the API to find features that have reached a specific Baseline threshold.\r\n\r\nThis API can be useful for tooling where you need to quickly get information about specific features. For example, you could use this type of tooling to write a script that tells you on some interval which features have become recently Baseline Newly available or Widely available. If this sounds like something useful to you, give the post a read!\r\n\r\nHow to think about Baseline and polyfills\r\nBaseline&#039;s mission is to bring clarity to which features you can safely use—but even with that added clarity, you still have to think about how to adopt features in a way that makes sense for your web applications. Polyfills are a big part of that process. Baseline doesn&#039;t consider polyfills in whether features are Newly or Widely available, and it doesn&#039;t try to tell you whether to use them. That decision is specific to your application, but it&#039;s an important consideration!\r\n\r\nRecently, we published a post on how to think about Baseline and polyfills, and we think it provides a helpful framework for how to think about using them. The hope with features that become Baseline Newly or Widely available is that polyfills become less of a necessity. There&#039;s no doubt that polyfills are useful tools in your development toolbox, but they have disadvantages—they can have a negative impact on your website&#039;s performance, and in some cases, there can even be accessibility concerns. Hopefully this guide helps you to navigate this tricky question!\r\n\r\ncontenteditable=&quot;plaintext-only&quot; is now Baseline Newly available\r\nThe contenteditable attribute on an HTML element allows the user to change its contents as though it were a text field. This means, for example, you could place the attribute on a  element and the user can interact with it like a . In some use cases, using contenteditable offers advantages over typical form elements.\r\n\r\nHowever, users paste stuff into editable elements, and the stuff they paste can contain rich text formatting, which can provide a frustrating experience for users who just want to paste unformatted text into a field. The contenteditable=&quot;plaintext-only&quot; attribute/value combination prevents this from happening, and it recently became Baseline Newly available. To find out more, read the announcement post, and learn how you can provide a better editing experience for users who just want to paste text into things without all of the fluff.\r\n\r\nIntl.DurationFormat is now Baseline Newly available\r\nYou&#039;ve probably been on a website at some point in your life and have seen a bit of text that communicates the duration of time until, or after some event, often in a string like &quot;2 days, 6 hours, 3 minutes&quot;. This data is useful for communicating any number of timely things, but it&#039;s often provided by a library. On top of that, you might want to output this information in multiple languages.\r\n\r\nEnter Intl.DurationFormat, an internationalization feature that has recently become Baseline Newly available. With the Intl.DurationFormat class, you can pass an object to its constructor containing the units of time you want formatted into a string, and in almost any language you can think of:', '6802f75fd0557_Screenshot 2025-04-19 090730.jpg', 86, '2025-04-19 09:07:43', '2025-04-19 09:07:43'),
(205, 'When to choose GitHub-Hosted runners or self-hosted runners with GitHub Actions', 'Comparing GitHub-hosted vs self-hosted runners for your CI/CD workflows? This deep dive explores important factors to consider when making this critical infrastructure decision for your development team.', 'Whether it’s building, testing, or deploying code, automating manual processes is key to improving developer experience and achieving a successful DevOps strategy.\r\n\r\nOn GitHub, you can use GitHub Actions to not only implement your CI/CD pipeline, but also automate other processes both on and off GitHub. When you are adopting GitHub Actions on GitHub Enterprise Cloud, you can choose between GitHub-hosted runners and self-hosted runners to run your workloads, and each has its pros and cons.\r\n\r\nIn this post, we’ll compare GitHub-hosted runners with self-hosted runners across five areas to help you determine which type best fits your GitHub Actions adoption strategy.\r\n\r\nWhat are GitHub-hosted runners and self-hosted runners?\r\nGitHub-hosted runners and self-hosted runners are based on the same open-source software and both support macOS, Windows, and Linux. But they have many differences.\r\n\r\nGitHub-hosted runners are fully managed on GitHub’s infrastructure using pre-configured Windows, Linux, and macOS virtual machines. In addition to offering standard runners for typical workloads, hosted runners offer larger runners with more resources (memory, CPU, and storage), custom images, static IP ranges, and Azure Virtual Network integration for enhanced security control.\r\n\r\nSelf-hosted runners operate on your own infrastructure, whether on-premises or in the cloud. You manage all aspects—configuration, security, and scaling. They also allow you to operate runners in places you couldn’t otherwise—for example, on GitHub Enterprise Server or on custom hardware. They can also be the only way to implement certain compliance requirements, especially when working with highly secured systems.\r\n\r\nBoth options offer distinct advantages depending on your specific needs and resources. Let’s explore when GitHub-hosted runners may be the right choice for your projects, and when it may be better to use self-hosted runners.\r\n\r\nFully managed or self-managed?\r\nA key distinction between these two options is where they’re hosted, as we’ve pointed out. But that choice comes with several implications.\r\n\r\nGitHub-hosted runners provide managed infrastructure with pools of on-demand virtual machines (VMs) that are automatically secured and updated. The environments are ephemeral, with the disks reimaged after each job, preventing files from previous jobs from affecting subsequent runs. The VMs are optimized for GitHub Actions, with pre-installed software and tools, including the latest versions of GitHub CLI, Docker, and common development platforms to ensure fast start times and avoid rate limits.\r\n\r\nWith GitHub-hosted runners, you can jump right in and start building workflows. There’s nothing to configure or secure before you start, making them ideal when you want to get started quickly. And we all prefer to spend more time on code than infrastructure, right?\r\n\r\nSelf-hosted runners offer you complete flexibility in defining your solution, but also means you are responsible for managing the infrastructure, images, caches, and security, and monitoring availability and usage against GitHub’s rate limits. This requires expertise in GitHub Actions architecture, VM and container image building, and network and infrastructure management. If your core business offering is scalable infrastructure solutions or Kubernetes, self-hosted runners may make sense.\r\n\r\nLet’s take a closer look.\r\n\r\nScalability\r\nTo remain productive, it’s important to have highly-available resources available on demand, especially for CI/CD workloads, where waiting for a job to run may mean you’re blocked from working on other tasks. In fact, a single wasted hour each week can cost a company over $4,000 a year per developer!\r\n\r\nBut scaling highly available, on-demand resources is hard. Even with a well-designed cloud infrastructure, it takes time to provision new virtual machines. You need systems in multiple regions to maintain up time, with 20-25% spare capacity to scale quickly and handle unexpected system failures.\r\n\r\nGitHub-hosted runners take advantage of Microsoft’s deep data center and cloud expertise and have dedicated teams to meet our service level agreement (SLA) of 99.9% availability. And that’s without any expertise on your part. In fact, many teams consider self-hosted runners in hopes of beating this availability, but it turns out that’s not even technically possible, as all runnings depend on the same services and control plane. That said, there are conditions where self-hosted runners may work for you.\r\n\r\nSelf-hosted runners may meet your needs if you need a fixed number of servers, are primarily focused on deployment to non-cloud resources, and don’t need to scale on demand. Just remember that the instances are not natively ephemeral, so you’ll need to have a strategy to keep the instances free from artifacts created by earlier runs. Self-hosted runners also lack automatic scaling capabilities; they require a scaling solution to be able to support large teams or create new instances dynamically.\r\n\r\nGitHub’s Actions Runner Controller (ARC) offers a solution, but it has limitations as it requires Kubernetes expertise and only supports Linux runners. Kubernetes relies on containers instead of VMs, which can require you to troubleshoot resource contention and scaling issues. ARC can also offer high availability by having multiple clusters. As we noted before, if your primary business is hosting and managing Kubernetes clusters, then ARC may be the right approach.\r\n\r\nARC does not support macOS or Windows workloads, and both environments present a number of limitations. For example, on macOS, you are required to use Apple hardware, you are limited to two VMs per machine, and containerizing the Apple runtime is not supported. For Windows, virtual machines are supported, but you need a custom orchestrator for scaling the instances. While you can create Windows containers and manage them with Kubernetes, the containers have slow startup times and may not support some of the necessary development and testing tools.\r\n\r\nIn short, we recommend GitHub-hosted runners for both macOS and Windows workloads.\r\n\r\nSecurity\r\nSecurity is critical for CI/CD processes, since they may require access to internal or production resources, and builds often use third-party libraries, runtimes, and tools, which can create a large attack surface if not properly secured.\r\n\r\nGitHub-hosted runners provide built-in security through a defense-in-depth, zero-trust approach. VMs provide network isolation, preventing exposure to other runners and corporate resources. In fact, access to corporate or cloud resources requires elevating privileges (we recommend OIDC). Their ephemeral nature eliminates code persistence and prevents application execution after job completion, reducing unauthorized access risks.\r\n\r\nStorage disks for hosted runners are encrypted at rest, ensuring the code is protected on the disk. All communications are encrypted to GitHub, and deployments to Microsoft Azure are routed through the Azure backbone, minimizing transits through the public internet. We provide regular security updates to both operating systems and runner software. The minimized attack surface and reduced risk of security breaches are key factors in the Department of Defense DevSecOps Reference Design’s recommendation to prefer GitHub-hosted runners for workloads up to Impact Level 5.\r\n\r\nSelf-hosted runners shift security responsibility entirely to you, requiring management of network, infrastructure, images, containers, and caches—that’s a lot of work. You also need to keep everything up to date, as runners connected to GitHub Enterprise Cloud will not be able to connect if they are more than 30 days behind the current release.\r\n\r\nNot to mention, if you operate runners within your network environment with access to corporate resources and production environments, you’ll want to implement a zero-trust, defense-in-depth strategy with time-limited resource access, which demands a high level of network security expertise.\r\n\r\nFinally, you’ll need to implement and keep updated both a tool cache and an Actions archive cache. Otherwise, you’re likely to encounter our rate limits as you scale up.\r\n\r\nTroubleshooting\r\nKeeping you productive means that problems with workflows or jobs—lack of resources, network issues, outages—need to be solved quickly. As a result, it’s important to have a support strategy.\r\n\r\nGitHub-hosted runners come with 24/7 support across all time zones, with premium plans offering dedicated reliability engineers and rapid 30-minute response times for critical issues. This eliminates the need for infrastructure troubleshooting on your part. GitHub handles all runner environment issues, from performance problems to queue times, letting you focus on development while we roll up our sleeves, figure out the problems, and get them fixed.\r\n\r\nSelf-hosted runners, however, shift first-level support responsibility to you, which means someone will have to troubleshoot performance, network, or queueing issues when they happen, leaving less time for the fun coding stuff. 🙁\r\n\r\nNot only that, but GitHub can only assist with the Actions service itself; we cannot assist with your infrastructure, Kubernetes clusters, or custom orchestration solutions. So if they figure out the issue is with your system, you’ll be on your own to solve it. Without sufficient planning, you can spend a lot of time waiting for a solution that lets you get back to writing and deploying code. That can be a big price to pay for self-hosted runners.\r\n\r\nCost management\r\nFinally, there’s the issue of cost. If you are offering Kubernetes or infrastructure management solutions, self-hosted runners may have some advantages. If not, then GitHub-hosted runners are likely the answer here too.\r\n\r\nGitHub-hosted runners operate on a pay-as-you-go model with no upfront costs or commitments. Teams optimize expenses through workflow improvements and appropriate runner selection. In addition, there are built-in cost savings. For example, GitHub doesn’t charge network egress fees—a significant advantage when working with large container images on cloud platforms. GitHub also has a partnership with Docker that allows unlimited image pulls from Docker Hub by GitHub-hosted runners, which often eliminates the need to create a pass-through registry or purchase business licenses for your CI/CD processes. Maintaining, supporting, and securing the environment is handled by GitHub, avoiding additional staff and service expenses. Finally, Enterprise accounts benefit from 50,000 free monthly minutes for standard runners.\r\n\r\nSelf-hosted runners, as in other areas, means organizations assume responsibility for all infrastructure, network, storage, security, and support costs. This gives you a lot of flexibility in defining the environment, right-sizing your resources, and customizing the networking. While per-minute virtual machine expenses might initially seem lower, the total ownership cost can (and often does) exceed GitHub-hosted solutions when accounting for these additional support costs.\r\n\r\nWhich runner is best for you?\r\nChoosing the right runner depends on your specific needs. Self-hosted runners are most suitable when using GitHub Enterprise Server (which lacks hosted runners), if your core business involves managing infrastructure or Kubernetes, or when you have compliance requirements not met by GitHub Enterprise Cloud with data residency. Scaling and ephemerality challenges make self-hosting less ideal for Windows and macOS workloads. If self-hosting is necessary, consider a hybrid approach and use self-hosted runners just for the specific workloads where they are needed.\r\n\r\nFor most developers and the vast majority of scenarios, unless you have very unique requirements or are willing to deeply invest in infrastructure to keep your CI/CD system humming, GitHub-hosted runners are likely your best option. They’re especially beneficial for those new to GitHub Actions and they let you spend your time focused on business value, new ideas, and writing code—instead of managing runners.', '6802fa6cef9da_wallpaper_github_generic_3.webp', 97, '2025-04-19 09:20:44', '2025-04-19 09:20:44'),
(206, 'Cracking the code: How to wow the acceptance committee at your next tech event', 'Want to speak at a tech conference? These four practical tips will help your session proposal stand out—and land you on the stage.', 'GitHub Universe returns to San Francisco on October 28 and 29—bringing together the builders, dreamers, and changemakers shaping the future of software. From first-time speakers with big ideas to DevRel pros with demos to share and business leaders rethinking workflows with AI, we believe that a diverse range of voices belong on our stage.\r\n\r\nBut writing a compelling conference session submission can feel like decoding a complex algorithm. What makes your idea stand out? How do you grab the content committee’s attention? And what if you’ve never done this before?\r\n\r\nGood news: we’ve cracked the code, and we’re sharing it with you.\r\n\r\nHere are four proven tips to help you put together a proposal that’s clear, compelling, and uniquely you.\r\n\r\nApply to speak or nominate a speaker to take the stage at GitHub Universe by Friday, May 2 at 11:59 pm PT to be considered.\r\n1. Find something you’re truly passionate about 💡\r\nA Venn diagram titled &#039;Signature talk formula&#039; showing the intersection of three circles labeled &#039;What you know&#039;, &#039;What you are passionate about&#039;, and &#039;What the audience cares about&#039;. The diagram is displayed on a dark background with the circles in blue, teal, and purple, illustrating how effective talks should combine knowledge, passion, and audience relevance.\r\n\r\nHere’s the truth: passion is magnetic. If you’re excited about your topic, it shows. It pulses through your proposal, powers your delivery onstage, and pulls in your audience—content committee included.\r\n\r\nInstead of chasing the latest trends, talk about something that lights you up. Maybe it’s a story from building an open source project in your off-hours. Maybe it’s how your team shipped something new using GitHub Copilot. Or maybe it’s the unexpected way you quickly scaled developer experience across a global org. Your unique perspective is your superpower.\r\n\r\nContent committees can sense authenticity. They’re not just looking for polished buzzwords. They’re looking for people who care deeply and can teach others something meaningful.\r\n\r\n🎤 Pro tip: If it’s a topic you’d talk about over lunch with a teammate or geek out about on a podcast, it’s probably a great fit.\r\n\r\n2. Write a title they can’t ignore ✍️\r\nThink of your session title like an email subject line—it’s your chance to make a strong first impression, and it needs to do the heavy lifting for you. A strong title shouldn’t just sound good. It should clearly communicate what your talk is about and why it matters.\r\n\r\nLet’s take our title as an example:\r\n\r\n✅ Engaging: “Cracking the Code” suggests there’s an inside strategy, and it sparks curiosity.\r\n✅ Clear: “How to wow the acceptance committee at your next tech event” leaves no doubt about the topic.\r\n\r\n✅ Action-oriented: It promises practical takeaways, not just theory.\r\n\r\n✅ Balanced: It walks the line between fun and professional.\r\n\r\nAvoid vague titles (“A new approach to software”) or clickbait (“This one trick will fix your codebase”). Instead, aim for clarity with flair. Give the content committee a reason to want to learn more along with the confidence that your talk can deliver.\r\n\r\n🎤 Pro tip: After you write your title, ask yourself—would I attend this session? Would I understand what I’m getting from it in five seconds?', '6802faf089359_1200x630-Universe_Blog_Banner.webp', 96, '2025-04-19 09:22:56', '2025-04-19 09:22:56'),
(207, 'How to make your images in Markdown on GitHub adjust for dark mode and light mode', 'When you want your images to look good in Markdown on GitHub, you might have to adjust for the UI around them.', 'GitHub supports dark mode and light mode, and as developers, we can make our README images look great in both themes. Here’s a quick guide to using the  element in your GitHub Markdown files to dynamically switch images based on the user’s color scheme.\r\n\r\nWhen developers switch to GitHub’s dark mode (or vice versa), standard images can look out of place, with bright backgrounds or clashing colors.\r\n\r\nInstead of forcing a one-size-fits-all image, you can tailor your visuals to blend seamlessly with the theme. It’s a small change, but it can make your project look much more polished.\r\n\r\nOne snippet, two themes!\r\nHere’s the magic snippet you can copy into your README (or any Markdown file):\r\n\r\n\r\n  \r\n  \r\n  \r\n\r\nNow, we say it’s magic, but let’s take a peek behind the curtain to show how it works:\r\n\r\nThe  tag lets you define multiple image sources for different scenarios.\r\nThe  attribute matches the user’s color scheme.\r\nWhen media=&quot;(prefers-color-scheme: dark)&quot;, the browser loads the srcset image when GitHub is in dark mode.\r\nSimilarly, when media=&quot;(prefers-color-scheme: light)&quot;, the browser loads the srcset image when GitHub is in light mode.\r\nIf the browser doesn’t support the  element, or the user’s system doesn’t match any defined media queries, the fallback  tag will be used.\r\nYou can use this approach in your repo README files, documentation hosted on GitHub, and any other Markdown files rendered on GitHub.com!', '68030f4322d1d_darklight.webp', 96, '2025-04-19 10:49:39', '2025-04-19 10:49:39'),
(208, 'Which AI model should I use with GitHub Copilot?', 'Ever wondered which AI model is the best fit for your GitHub Copilot project? Here are some things to consider.', 'This was originally published on our developer newsletter, GitHub Insider, which offers tips and tricks for devs at every level. If you’re not subscribed, go do that now—you won’t regret it (we promise).\r\n\r\nIf you’ve ever wondered which AI model is the best fit for your GitHub Copilot project, you’re not alone. Since each model has its own strengths, picking the right one can feel somewhat mysterious.\r\n\r\nBig disclaimer!\r\n\r\nAI moves fast, so these recommendations are subject to change. It’s mid-April 2025 right now, though things will probably be different within a week of posting. Zoom zoom zoom.\r\n\r\nWith models that prioritize speed, depth, or a balance of both, it helps to know what each one brings to the table. Let’s break it down together. 👇\r\n\r\nThe TL;DR\r\n💳 Balance between cost and performance: Go with GPT-4.1, GPT-4o, or Claude 3.5 Sonnet.\r\n🪙 Fast, lightweight tasks: o4-mini or Claude 3.5 Sonnet are your buddies.\r\n💎 Deep reasoning or complex debugging: Think Claude 3.7 Sonnet, o3, or GPT 4.5.\r\n🖼️ Multimodal inputs (like images): Check out Gemini 2.0 Flash or GPT-4o.\r\nYour mileage may vary and it’s always good to try things yourself before taking someone else’s word for it, but this is how these models were designed to be used. All that being said…\r\n\r\nLet’s talk models.\r\n\r\n🏎️ Putting coding speed first\r\no4-mini and o3-mini: The speed demons 😈\r\nFast, efficient, and cost-effective, o4-mini and o3-mini are ideal for simple coding questions and quick iterations. If you’re looking for a no-frills model, use these.\r\n\r\n✅ Use them for:\r\n\r\nQuick prototyping.\r\nExplaining code snippets.\r\nLearning new programming concepts.\r\nGenerating boilerplate code.\r\n👀 You may prefer another model: If your task spans multiple files or calls for deep reasoning, a higher‑capacity model such as GPT‑4.5 or o3 can keep more context in mind. Looking for extra expressive flair? Try GPT‑4o.\r\n\r\n⚖️ AI models designed for balance\r\nClaude 3.5 Sonnet: The budget-friendly helper 😊\r\nNeed solid performance but watching your costs? Claude 3.5 Sonnet is like a dependable sidekick. It’s great for everyday coding tasks without burning through your monthly usage.\r\n\r\n✅ Use it for:\r\n\r\nWriting documentation.\r\nAnswering language-specific questions.\r\nGenerating code snippets.\r\n👀 You may prefer another model: For elaborate multi‑step reasoning or big‑picture planning, consider stepping up to Claude 3.7 Sonnet or GPT‑4.5.\r\n\r\nGPT-4o and GPT-4.1: The all-rounders 🌎\r\nThese are your go-to models for general tasks. Need fast responses? Check. Want to work with text *and* images? Double check. GPT-4o and GPT-4.1 are like the Swiss Army knives of AI models: flexible, dependable, and cost-efficient.\r\n\r\n✅ Use them for:\r\n\r\nExplaining code blocks.\r\nWriting comments or docs.\r\nGenerating small, reusable snippets.\r\nMultilingual prompts.\r\n👀 You may prefer another model: Complex architectural reasoning or multi‑step debugging may land more naturally with GPT‑4.5 or Claude 3.7 Sonnet.\r\n\r\n🧠 Models for deep thinking and big projects\r\nClaude 3.7 Sonnet: The architect 🏠\r\nThis one’s the power tool for large, complex projects. From multi-file refactoring to feature development across front end and back end, Claude 3.7 Sonnet shines when context and depth matter most.\r\n\r\n✅ Use it for:\r\n\r\nRefactoring large codebases.\r\nPlanning complex architectures.\r\nDesigning algorithms.\r\nCombining high-level summaries with deep analysis.\r\n👀 You may prefer another model: For quick iterations or straightforward tasks, Claude 3.5 Sonnet or GPT‑4o may deliver results with less overhead.\r\n\r\nGemini 2.5 Pro: The researcher 🔎\r\nGemini 2.5 Pro is the powerhouse for advanced reasoning and coding. It’s built for complex tasks (think: deep debugging, algorithm design, and even scientific research). With its long-context capabilities, it can handle extensive datasets or documents with ease.\r\n\r\n✅ Use it for:\r\n\r\nWriting full functions, classes, or multi-file logic.\r\nDebugging complex systems.\r\nAnalyzing scientific data and generating insights.\r\nProcessing long documents, datasets, or codebases.\r\n👀 You may prefer another model: For cost-sensitive tasks, o4-mini or Gemini 2.0 Flash are more budget-friendly options.\r\n\r\nGPT-4.5: The thinker 💭\r\nGot a tricky problem? Whether you’re debugging multi-step issues or crafting full-on systems architectures, GPT-4.5 thrives on nuance and complexity.\r\n\r\n✅ Use it for:\r\n\r\nWriting detailed README files.\r\nGenerating full functions or multi-file solutions.\r\nDebugging complex errors.\r\nMaking architectural decisions.\r\n👀 You may prefer another model: When you just need a quick iteration on something small—or you’re watching tokens—GPT‑4o can finish faster and cheaper.\r\n\r\no3 and o1: The deep diver 🥽\r\nThese models are perfect for tasks that need precision and logic. Whether you’re optimizing performance-critical code or refactoring a messy codebase, o3 and o1 excel in breaking down problems step by step.\r\n\r\n✅ Use them for:\r\n\r\nCode optimization.\r\nDebugging complex systems.\r\nWriting structured, reusable code.\r\nSummarizing logs or benchmarks.\r\n👀 You may prefer another model: During early prototyping or lightweight tasks, a nimble model such as o4‑mini or GPT‑4o may feel snappier.\r\n\r\n🖼️ Multimodal, or designed to handle it all\r\nGemini 2.0 Flash: The visual thinker 🤔\r\nGot visual inputs like UI mockups or diagrams? Gemini 2.0 Flash lets you bring images into the mix, making it a great choice for front-end prototyping or layout debugging.\r\n\r\n✅ Use it for:\r\n\r\nAnalyzing diagrams or screenshots.\r\nDebugging UI layouts.\r\nGenerating code snippets.\r\nGetting design feedback.\r\n👀 You may prefer another model: If the job demands step‑by‑step algorithmic reasoning, GPT‑4.5 or Claude 3.7 Sonnet will keep more moving parts in scope.\r\n\r\nSo… which model do I choose?\r\nHere’s the rule of thumb: Match the model to the task. Practice really does make perfect, and as you work with different models, it’ll become clearer which ones work best for different tasks. The more I’ve personally used certain models, the more I’ve learned, “oh, I should switch for this particular task,” and “this one will get me there.”\r\n\r\nAnd because I enjoy staying employed, I would love to cheekily mention that you can (and should!) use these models with…\r\n\r\nGitHub Copilot in your favorite IDE\r\nGitHub Copilot on GitHub.com\r\nWith agent mode or Copilot Edits\r\nWith agent mode in Codespaces\r\nWith agent mode in VS Code\r\nGood luck, go forth, and happy coding!', '680312018dd98_wallpaper_copilot_generic_logo.webp', 98, '2025-04-19 11:01:21', '2025-04-19 11:01:21');

-- --------------------------------------------------------

--
-- Table structure for table `users`
--

CREATE TABLE `users` (
  `id` int(10) UNSIGNED NOT NULL,
  `username` varchar(50) NOT NULL,
  `password` varchar(255) NOT NULL,
  `created_at` datetime NOT NULL DEFAULT current_timestamp()
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `users`
--

INSERT INTO `users` (`id`, `username`, `password`, `created_at`) VALUES
(86, 'jake1', '$2y$10$Bh/2fisC.gqBKdnjU9fw/.KhvA76ehLDAvqOSolgvIP7lkY2LEeqK', '2025-01-14 17:04:33'),
(96, 'jake', '$2y$10$24S5VTQmZ2YNQWGwpL4txOHajNYmj4l0ggvV.XepXz58hvh6PhUt2', '2025-04-19 09:13:05'),
(97, 'jake2', '$2y$10$87F.pfEocVjl/yEXJJci1u7FSH/1QL7JMeudO.pUN8XD6lyVQsc9u', '2025-04-19 09:17:38'),
(98, 'jake3', '$2y$10$mjj8Z3B9Ph4kC1Wt7o78ieJH7o6Ur0s029IevgWxPu.hASYeBCcI2', '2025-04-19 11:00:08');

--
-- Indexes for dumped tables
--

--
-- Indexes for table `blogs`
--
ALTER TABLE `blogs`
  ADD PRIMARY KEY (`id`),
  ADD KEY `author_id` (`author_id`);

--
-- Indexes for table `users`
--
ALTER TABLE `users`
  ADD PRIMARY KEY (`id`);

--
-- AUTO_INCREMENT for dumped tables
--

--
-- AUTO_INCREMENT for table `blogs`
--
ALTER TABLE `blogs`
  MODIFY `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=209;

--
-- AUTO_INCREMENT for table `users`
--
ALTER TABLE `users`
  MODIFY `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=99;

--
-- Constraints for dumped tables
--

--
-- Constraints for table `blogs`
--
ALTER TABLE `blogs`
  ADD CONSTRAINT `blogs_ibfk_1` FOREIGN KEY (`author_id`) REFERENCES `users` (`id`) ON DELETE CASCADE;
COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
